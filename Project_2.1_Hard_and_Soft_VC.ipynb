{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRlRALH-IjLm"
   },
   "source": [
    "# Project 2 - Part II: Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 1: Hard & Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uxYNNbOIjLo"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQF40vGpIjLr"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GBZ4MrQZIjLs",
    "outputId": "f8b3cc4d-3c8b-4856-c7ad-8622b6f4bc4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115459, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_df = pd.read_csv(r'revised_hotel_df.csv')\n",
    "hotel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "kRiV_TSiIjLw",
    "outputId": "a1804636-4c79-4f95-878e-451d9cac07de",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hotel', 'is_canceled', 'lead_time', 'arrival_date_month',\n",
       "       'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'meal',\n",
       "       'country', 'distribution_channel', 'is_repeated_guest',\n",
       "       'previous_cancellations', 'previous_bookings_not_canceled',\n",
       "       'assigned_room_type', 'booking_changes', 'deposit_type',\n",
       "       'days_in_waiting_list', 'customer_type', 'adr', 'under_18'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DEZLcLxIjLz"
   },
   "source": [
    "### Evaluation Metric Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_52MhJcIjLz"
   },
   "source": [
    "From Project 1, we decided that the chosen evaluation metric is recall. The goal is the produce a model with a __high recall__ rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KEZebfYcIjL0"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4JDierLIjL1"
   },
   "outputs": [],
   "source": [
    "    # one hot encode the categorical variables\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['hotel'], prefix='hotel')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['arrival_date_month'], prefix='month')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['meal'], prefix='meal')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['country'], prefix='country')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['distribution_channel'], prefix='distr')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['assigned_room_type'], prefix='room')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['deposit_type'], prefix='deposit')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['customer_type'], prefix='cust')\n",
    "#hotel_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hg6-NMp3IjL4"
   },
   "source": [
    "Column rearrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f63bYKy-IjL4"
   },
   "outputs": [],
   "source": [
    "hotel_df.insert(5, 'under_18', hotel_df.pop('under_18'))\n",
    "hotel_df.insert(11, 'is_repeated_guest', hotel_df.pop('is_repeated_guest'))\n",
    "#hotel_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VAcf5rhJIjMh"
   },
   "source": [
    "Hard Voting Classifier requires high computing power. Due to limited resources, we are forced to cut the sample size. But again, we make sure that the proportion of cancelled reservations in this sample is about the same as in the original dataset, which was ~37%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4TJHJy1IjMN"
   },
   "outputs": [],
   "source": [
    "hotel_df_sample = hotel_df.copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kPFu-84lO4Fq",
    "outputId": "d60cf13b-852a-4a75-9f8b-b816b8b7be3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6240\n",
       "1    3760\n",
       "Name: is_canceled, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_df_sample = hotel_df.sample(n=10000, random_state=8860).reset_index(drop=True)\n",
    "hotel_df_sample['is_canceled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y6i8XaaeIjMP"
   },
   "outputs": [],
   "source": [
    "X = hotel_df_sample.drop('is_canceled', axis=1)\n",
    "y = hotel_df_sample['is_canceled']\n",
    "#X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yh5qJ2ASIjMT"
   },
   "source": [
    "Train-test split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EM7q-dbkIjMU"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ozg2vzzSIjMX"
   },
   "outputs": [],
   "source": [
    "    # Standard Scaler is usually preferred b/c helps you account for outliers & keeps dispersion\n",
    "scaler = StandardScaler()\n",
    "\n",
    "    # fit_transform for train data set, but just the numerical columns, not one-hot encoded columns\n",
    "X_train.iloc[ : , 0:10] = scaler.fit_transform(X_train.iloc[ : , 0:10])\n",
    "X_test.iloc[ : , 0:10] = scaler.transform(X_test.iloc[ : , 0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGaZybNvIjL8"
   },
   "source": [
    "## Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PB36PClzIjMM"
   },
   "source": [
    "### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "OP5t0MS5IjMa",
    "outputId": "dbcc265f-be6d-4c19-fda9-a524111d3e88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # instantiate with best hyperparameter found in project 1\n",
    "logreg = LogisticRegression(random_state=123, C=100)\n",
    "\n",
    "    # fit on training set\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AR3F2zkTIjMg"
   },
   "source": [
    "### Model 2: Kernelized SVM (poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uA24kHkgIjMr"
   },
   "outputs": [],
   "source": [
    "    # instantiate, with best hyperparameters found in Project 1\n",
    "    # need for probability to = True in order to run soft Voting Classifier\n",
    "SVM2 = SVC(kernel='poly', random_state=123, C = 0.001, gamma = 1, degree = 3, probability = True)\n",
    "    \n",
    "    # fit on training data set\n",
    "SVM2 = SVM2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnG2OzE6IjMy"
   },
   "source": [
    "### Model 3: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "lh22eKqkIjM7",
    "outputId": "d355997d-6afa-43b8-e549-49746b914930"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "                       max_features=None, max_leaf_nodes=9,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # instantiate decision tree\n",
    "dtree = DecisionTreeClassifier(random_state=123, max_depth=5, max_leaf_nodes=9, min_samples_split=2)\n",
    "\n",
    "    # fit with best hyperparameters found in Project 1\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOpeiQY-IjM9"
   },
   "source": [
    "Now that we've fit the training data sets to all the models, we can move on to more advanced algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3q9eHxS8IjM9"
   },
   "source": [
    "### Hard Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZfGqNcyaIjM-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logreg',\n",
       "                              LogisticRegression(C=100, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=123,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('SVM, kernel: poly',\n",
       "                              SVC(C=0.001, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, de...\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             ('Dtree',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=5,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=9,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort=False,\n",
       "                                                     random_state=123,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=-1, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_voting_clf = VotingClassifier(estimators=[('logreg', logreg), ('SVM, kernel: poly', SVM2),\n",
    "                                               ('Dtree', dtree)],\n",
    "                              voting='hard', n_jobs=-1)\n",
    "hard_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3q9eHxS8IjM9"
   },
   "source": [
    "### Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZfGqNcyaIjM-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logreg',\n",
       "                              LogisticRegression(C=100, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=123,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('SVM, kernel: poly',\n",
       "                              SVC(C=0.001, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, de...\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             ('Dtree',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=5,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=9,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort=False,\n",
       "                                                     random_state=123,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=-1, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_voting_clf = VotingClassifier(estimators=[('logreg', logreg), ('SVM, kernel: poly', SVM2),\n",
    "                                               ('Dtree', dtree)],\n",
    "                              voting='soft', n_jobs=-1)\n",
    "soft_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.789\n",
      "SVC 0.801\n",
      "DecisionTreeClassifier 0.7565\n",
      "VotingClassifier 0.8015\n",
      "VotingClassifier 0.7975\n"
     ]
    }
   ],
   "source": [
    "for clf in (logreg, SVM2, dtree, hard_voting_clf, soft_voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Recall Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l6Rq7eSLxgMv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.5585106382978723\n",
      "SVC 0.6023936170212766\n",
      "DecisionTreeClassifier 0.586436170212766\n",
      "VotingClassifier 0.574468085106383\n",
      "VotingClassifier 0.535904255319149\n"
     ]
    }
   ],
   "source": [
    "for clf in (logreg, SVM2, dtree, hard_voting_clf, soft_voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocqmajvvIjNF"
   },
   "source": [
    "### Model Summaries & Best Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfB-XVoFIjNG"
   },
   "source": [
    "|   | Model Name | Recall Score | \n",
    "| - | ---------- | ----------- | \n",
    "| 1 | Logistic Regression  |  0.5585 |\n",
    "| 2 | SVM, kernel='poly'  | 0.6024 | \n",
    "| 3 | Decision Tree  | 0.5864 | \n",
    "| 4 | Hard Voting Classifier  | 0.5745 |\n",
    "| 5 | Soft Voting Classifier  | 0.5359 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXHEpFwgIjNG"
   },
   "source": [
    "Amongst the recall scores, SVM with poly kernel gives the highest performance. Neither of the Voting Classifiers gives better recall score performance than the non-ensemble algorithms. In fact, the Soft Voting Classifier performs worse amongst this group of models."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Project_2_Draft.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
