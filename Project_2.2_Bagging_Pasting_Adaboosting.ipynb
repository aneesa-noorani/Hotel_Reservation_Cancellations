{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRlRALH-IjLm"
   },
   "source": [
    "# Project 2 - Part II: Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 2: Bagging, Pasting, Adaboosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uxYNNbOIjLo"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQF40vGpIjLr"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GBZ4MrQZIjLs",
    "outputId": "f8b3cc4d-3c8b-4856-c7ad-8622b6f4bc4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115459, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bonus = pd.read_csv(r'revised_hotel_df.csv')\n",
    "hotel_df = df_bonus.copy()\n",
    "hotel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "kRiV_TSiIjLw",
    "outputId": "a1804636-4c79-4f95-878e-451d9cac07de",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hotel', 'is_canceled', 'lead_time', 'arrival_date_month',\n",
       "       'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'meal',\n",
       "       'country', 'distribution_channel', 'is_repeated_guest',\n",
       "       'previous_cancellations', 'previous_bookings_not_canceled',\n",
       "       'assigned_room_type', 'booking_changes', 'deposit_type',\n",
       "       'days_in_waiting_list', 'customer_type', 'adr', 'under_18'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DEZLcLxIjLz"
   },
   "source": [
    "### Evaluation Metric Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_52MhJcIjLz"
   },
   "source": [
    "From Project 1, we decided that the chosen evaluation metric is recall. The goal is the produce a model with a __high recall__ rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KEZebfYcIjL0"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4JDierLIjL1"
   },
   "outputs": [],
   "source": [
    "    # one hot encode the categorical variables\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['hotel'], prefix='hotel')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['arrival_date_month'], prefix='month')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['meal'], prefix='meal')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['country'], prefix='country')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['distribution_channel'], prefix='distr')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['assigned_room_type'], prefix='room')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['deposit_type'], prefix='deposit')\n",
    "hotel_df = pd.get_dummies(hotel_df, columns = ['customer_type'], prefix='cust')\n",
    "#hotel_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hg6-NMp3IjL4"
   },
   "source": [
    "Column rearrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f63bYKy-IjL4"
   },
   "outputs": [],
   "source": [
    "hotel_df.insert(5, 'under_18', hotel_df.pop('under_18'))\n",
    "hotel_df.insert(11, 'is_repeated_guest', hotel_df.pop('is_repeated_guest'))\n",
    "#hotel_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wUD0DLtDIjL7"
   },
   "source": [
    "Need to take random sample, as the current data set is too large to run on a normal computer. We also make sure that the proportion of cancelled reservations is similar to the proportion observed in the original data set, which was ~37%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGaZybNvIjL8"
   },
   "source": [
    "## Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting sample data set ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kPFu-84lO4Fq",
    "outputId": "d60cf13b-852a-4a75-9f8b-b816b8b7be3f"
   },
   "outputs": [],
   "source": [
    "#hotel_df_sample = hotel_df.sample(n=50000, random_state=8860).reset_index(drop=True)\n",
    "#hotel_df_sample['is_canceled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y6i8XaaeIjMP"
   },
   "outputs": [],
   "source": [
    "X = hotel_df.drop('is_canceled', axis=1)\n",
    "y = hotel_df['is_canceled']\n",
    "#X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yh5qJ2ASIjMT"
   },
   "source": [
    "Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PB36PClzIjMM"
   },
   "source": [
    "### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1FJEXUqIjMW"
   },
   "source": [
    "Logistic regression is sensitive to scaling, so must scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EM7q-dbkIjMU"
   },
   "outputs": [],
   "source": [
    "X_train_logreg, X_test_logreg, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ozg2vzzSIjMX"
   },
   "outputs": [],
   "source": [
    "    # Standard Scaler is usually preferred b/c helps you account for outliers & keeps dispersion\n",
    "scaler = StandardScaler()\n",
    "\n",
    "    # fit_transform for train data set, but just the numerical columns, not one-hot encoded columns\n",
    "X_train_logreg.iloc[ : , 0:10] = scaler.fit_transform(X_train_logreg.iloc[ : , 0:10])\n",
    "X_test_logreg.iloc[ : , 0:10] = scaler.transform(X_test_logreg.iloc[ : , 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "OP5t0MS5IjMa",
    "outputId": "dbcc265f-be6d-4c19-fda9-a524111d3e88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # instantiate with best hyperparameter found in project 1\n",
    "logreg = LogisticRegression(random_state=123, C=100)\n",
    "\n",
    "    # fit on training set\n",
    "logreg.fit(X_train_logreg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, Recall score: 0.5230\n",
      "Logistic Regression, Accuracy score: 0.7755\n"
     ]
    }
   ],
   "source": [
    "y_pred_logreg = logreg.predict(X_test_logreg)\n",
    "print(\"Logistic Regression, Recall score: {:.4f}\".format(recall_score(y_test, y_pred_logreg)))\n",
    "print(\"Logistic Regression, Accuracy score: {:.4f}\".format(accuracy_score(y_test, y_pred_logreg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnG2OzE6IjMy"
   },
   "source": [
    "### Model 2: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_ZVB4StIjMz"
   },
   "source": [
    "Decision trees are also unable to handle categorical data. However, scaling doesn't make a difference in decision trees, so we will not scale the data. This means we need to recreate the same train-test split as we did for Logistic Regressionm, before we applied scaling to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63j96tk9IjM4"
   },
   "outputs": [],
   "source": [
    "X_train_dtree, X_test_dtree, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "lh22eKqkIjM7",
    "outputId": "d355997d-6afa-43b8-e549-49746b914930"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=9,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # instantiate decision tree\n",
    "dtree = DecisionTreeClassifier(random_state=123, max_depth=5, max_leaf_nodes=9, min_samples_split=2)\n",
    "\n",
    "    # fit with best hyperparameters found in Project 1\n",
    "dtree.fit(X_train_dtree, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree, Recall score: 0.5719\n",
      "Decision Tree, Accuracy score: 0.7668\n"
     ]
    }
   ],
   "source": [
    "y_pred_dtree = dtree.predict(X_test_dtree)\n",
    "print(\"Decision Tree, Recall score: {:.4f}\".format(recall_score(y_test, y_pred_dtree)))\n",
    "print(\"Decision Tree, Accuracy score: {:.4f}\".format(accuracy_score(y_test, y_pred_dtree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOpeiQY-IjM9"
   },
   "source": [
    "Now that we've fit the training data sets to all the models, we can move on to more advanced algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3a: Bagging 1, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # bootstrap = True : means with replacement. if False, no replacement\n",
    "bag_clf1 = BaggingClassifier(logreg, n_estimators=500, max_samples=100, bootstrap=True, \n",
    "                            random_state=0, n_jobs=-1, oob_score=True)\n",
    "\n",
    "bag_clf1.fit(X_train_logreg, y_train)\n",
    "y_pred1 = bag_clf1.predict(X_test_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging 1: Logistic Regression, Recall score: 0.5161\n",
      "Bagging 1: Logistic Regression, Accuracy score: 0.7750\n"
     ]
    }
   ],
   "source": [
    "print(\"Bagging 1: Logistic Regression, Recall score: {:.4f}\".format(recall_score(y_test, y_pred1)))\n",
    "print(\"Bagging 1: Logistic Regression, Accuracy score: {:.4f}\".format(accuracy_score(y_test, y_pred1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3b: Bagging 2, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # bootstrap = True : means with replacement. if False, no replacement\n",
    "bag_clf2 = BaggingClassifier(dtree, n_estimators=500, max_samples=100, bootstrap=True, \n",
    "                            random_state=0, n_jobs=-1, oob_score=True)\n",
    "\n",
    "bag_clf2.fit(X_train_dtree, y_train)\n",
    "y_pred2 = bag_clf2.predict(X_test_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging 2: Decision Tree, Recall score: 0.4011\n",
      "Bagging 2: Decision Tree, Accuracy score: 0.7671\n"
     ]
    }
   ],
   "source": [
    "print(\"Bagging 2: Decision Tree, Recall score: {:.4f}\".format(recall_score(y_test, y_pred2)))\n",
    "print(\"Bagging 2: Decision Tree, Accuracy score: {:.4f}\".format(accuracy_score(y_test, y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4a: Pasting 1, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # bootstrap = True : means with replacement. if False, no replacement\n",
    "past_clf1 = BaggingClassifier(logreg, n_estimators=500, max_samples=100, bootstrap=False, \n",
    "                            random_state=0, n_jobs=-1)\n",
    "\n",
    "past_clf1.fit(X_train_logreg, y_train)\n",
    "y_pred3 = past_clf1.predict(X_test_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting 1: Logistic Regression, Recall score: 0.5158\n",
      "Pasting 1: Logistic Regression, Accuracy score: 0.7748\n"
     ]
    }
   ],
   "source": [
    "print(\"Pasting 1: Logistic Regression, Recall score: {:.4f}\".format(recall_score(y_test, y_pred3)))\n",
    "print(\"Pasting 1: Logistic Regression, Accuracy score: {:.4f}\".format(accuracy_score(y_test, y_pred3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4b: Pasting 2, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # bootstrap = True : means with replacement. if False, no replacement\n",
    "past_clf2 = BaggingClassifier(dtree, n_estimators=500, max_samples=100, bootstrap=False, \n",
    "                            random_state=0, n_jobs=-1)\n",
    "\n",
    "past_clf2.fit(X_train_dtree, y_train)\n",
    "y_pred4 = past_clf2.predict(X_test_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting 2: Decision Tree, Recall score: 0.4018\n",
      "Pasting 2: Decision Tree, Accuracy score: 0.7673\n"
     ]
    }
   ],
   "source": [
    "print(\"Pasting 2: Decision Tree, Recall score: {:.4f}\".format(recall_score(y_test, y_pred4)))\n",
    "print(\"Pasting 2: Decision Tree, Accuracy score: {:.4f}\".format(accuracy_score(y_test, y_pred4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5a: Adaboosting 1, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf1 = AdaBoostClassifier(logreg, n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "\n",
    "ada_clf1.fit(X_train_logreg, y_train)\n",
    "y_pred5 = ada_clf1.predict(X_test_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboosting 1: Logistic Regression, Recall score: 0.5178\n",
      "Adaboosting 1: Logistic Regression, Accuracy score: 0.7680\n"
     ]
    }
   ],
   "source": [
    "print(\"Adaboosting 1: Logistic Regression, Recall score: {:.4f}\".format(recall_score(y_test, y_pred5)))\n",
    "print(\"Adaboosting 1: Logistic Regression, Accuracy score: {:.4f}\".format(accuracy_score(y_test, y_pred5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5b: Adaboosting 2, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf2 = AdaBoostClassifier(dtree, n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "\n",
    "ada_clf2.fit(X_train_dtree, y_train)\n",
    "y_pred6 = ada_clf2.predict(X_test_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboosting 2: Decision Tree, Recall score: 0.6826\n",
      "Adaboosting 2: Decision Tree, Accuracy score: 0.8189\n"
     ]
    }
   ],
   "source": [
    "print(\"Adaboosting 2: Decision Tree, Recall score: {:.4f}\".format(recall_score(y_test, y_pred6)))\n",
    "print(\"Adaboosting 2: Decision Tree, Accuracy score: {:.4f}\".format(accuracy_score(y_test, y_pred6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocqmajvvIjNF"
   },
   "source": [
    "### Model Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfB-XVoFIjNG"
   },
   "source": [
    "|   | Model Name |  Recall Score | Bagging Recall Score | Pasting Recall Score | Adaboosting Recall Score |\n",
    "| - | ---------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| 1 | Logistic Regression    | 0.5230 | 0.5161 | 0.5158 | 0.5178 |\n",
    "| 2 | Decision Tree  | 0.5719 | 0.4011 | 0.4018 | 0.6826 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXHEpFwgIjNG"
   },
   "source": [
    "Based on recall score for these 8 models, the Adaboosting Decision Tree model gives the best performance, at a recall of 68.26%.\n",
    "\n",
    "In the last notebook, the SVM poly kernel model performed best, but only at a recall of 60.24%. Thus, so far, the Adaboosting Decision Tree is the best model of all the ones we have run so far (including Voting Classifiers)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Project_2_Draft.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
